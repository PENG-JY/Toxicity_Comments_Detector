{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducion\n",
    "This script collects tweets containing the query \"AI Art\" to support an exploration of online toxicity within discussions about artificial intelligence and digital art. It employs the Tweepy library for interfacing with the Twitter API, using multiple API keys to manage rate limits dynamically. The script retrieves tweets in batches, handles pagination with a \"next token\" mechanism, and includes error handling for rate limits and other issues. Collected tweets are deduplicated based on unique tweet IDs and saved in JSON format, including the tweet ID, text, and timestamp. The output will provide valuable data for analyzing themes, sentiments, and toxic behavior in this online discourse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEYS = [\n",
    "    \n",
    "    {\n",
    "        \"API_KEY\": 'Yours api key',\n",
    "        \"API_SECRET\": 'Your api secret',\n",
    "        \"BEARER_TOKEN\" :'Your bearer token',\n",
    "    },\n",
    "    \n",
    "  \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top topics\n",
    "- AI art ethical （done）\n",
    "- AI Killing Creativity （done）\n",
    "- AI Art Copyright (done) 70\n",
    "- AI Art Exploitation (done) 30\n",
    "- AI Art Fairness (done) 1\n",
    "- AI Art Soulless (done) 96\n",
    "- AI Art Theft (done) 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"AI Art Theft\" \n",
    "max_results = 100  \n",
    "total_tweets_to_fetch = 1000  \n",
    "pause_time = 30  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API key 1 grab themed tweets...\n",
      "Currently, a total of 99 topic tweets have been captured.\n",
      "Using API key 1 grab themed tweets...\n",
      "API key 1 has hit the rate limit, pausing for 0 minutes...\n",
      "Using API key 1 grab themed tweets...\n",
      "API key 1 has hit the rate limit, pausing for 0 minutes...\n",
      "Using API key 1 grab themed tweets...\n",
      "API key 1 has hit the rate limit, pausing for 0 minutes...\n",
      "All API keys have reached the rate limit, skipping comment fetching and saving data directly...\n",
      "A total of 99 topic tweets have been captured.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweets = []  \n",
    "next_token = None  \n",
    "current_api_index = 0  \n",
    "rate_limit_count = 0 \n",
    "total_rate_limit_count = 0 \n",
    "\n",
    "# Capture theme-related tweets\n",
    "while len(tweets) < total_tweets_to_fetch:\n",
    "    try:\n",
    "        # Change current API key\n",
    "        api = API_KEYS[current_api_index]\n",
    "        client = tweepy.Client(bearer_token=api[\"BEARER_TOKEN\"])\n",
    "        print(f\"Using API key {current_api_index + 1} grab themed tweets...\")\n",
    "\n",
    "        # Using API \n",
    "        response = client.search_recent_tweets(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            next_token=next_token\n",
    "        )\n",
    "\n",
    "\n",
    "        # if there has data, saving it to the list\n",
    "        if response.data:\n",
    "            tweets.extend(response.data)\n",
    "            print(f\"Currently, a total of {len(tweets)} topic tweets have been captured.\")\n",
    "\n",
    "        else:\n",
    "            print(\"No more tweets to capture.\")\n",
    "\n",
    "            \n",
    "\n",
    "        # Get paging token\n",
    "        next_token = response.meta.get(\"next_token\")\n",
    "        if not next_token:\n",
    "            print(f\"API key {current_api_index + 1} Grabbing has been completed.\")\n",
    "            current_api_index += 1  # change it to next API key\n",
    "            next_token = None  # Reset paging token\n",
    "            if current_api_index >= len(API_KEYS):  \n",
    "                print(\"All API keys have been used up.\")\n",
    "\n",
    "    except tweepy.TooManyRequests:\n",
    "        # Handle rate limit\n",
    "        print(f\"API key {current_api_index + 1} has hit the rate limit, pausing for {pause_time // 60} minutes...\")\n",
    "        time.sleep(pause_time)\n",
    "        rate_limit_count += 1  # Count the rate limit occurrences\n",
    "        total_rate_limit_count += 1  # Update total rate limit count\n",
    "\n",
    "        # If all API keys hit the rate limit, skip comment fetching and end fetching\n",
    "        if total_rate_limit_count >= len(API_KEYS) * 3:\n",
    "            print(\"All API keys have reached the rate limit, skipping comment fetching and saving data directly...\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle other errors\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# remove the duplicates\n",
    "unique_tweets = list({tweet.id: tweet for tweet in tweets}.values())\n",
    "\n",
    "\n",
    "# make it to json files\n",
    "tweet_data = [{\"id\": tweet.id, \"text\": tweet.text, \"created_at\": str(tweet.created_at)} for tweet in unique_tweets]\n",
    "\n",
    "\n",
    "# saving the files\n",
    "with open(\"tweets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweet_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"A total of {len(unique_tweets)} topic tweets have been captured.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
